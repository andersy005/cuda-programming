{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hello World From GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best way to learn a new programming language is by writing programs using the new language. In this section, we are going to write our first kernel code running on the GPU.\n",
    "\n",
    "First, let's check that the CUDA compiler is installed properly with the following command on a Linux system:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/local/cuda/bin/nvcc\n",
      "nvcc: NVIDIA (R) Cuda compiler driver\n",
      "Copyright (c) 2005-2017 NVIDIA Corporation\n",
      "Built on Fri_Nov__3_21:07:56_CDT_2017\n",
      "Cuda compilation tools, release 9.1, V9.1.85\n"
     ]
    }
   ],
   "source": [
    "!which nvcc\n",
    "!nvcc --version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check if a GPU accelerator card is attached in our machine:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "crw-rw-rw- 1 root root 195,   0 Jun 26 08:27 /dev/nvidia0\r\n",
      "crw-rw-rw- 1 root root 195, 255 Jun 26 08:27 /dev/nvidiactl\r\n",
      "crw-rw-rw- 1 root root 195, 254 Jun 26 08:28 /dev/nvidia-modeset\r\n",
      "crw-rw-rw- 1 root root 240,   0 Jun 26 08:28 /dev/nvidia-uvm\r\n"
     ]
    }
   ],
   "source": [
    "!ls -l /dev/nv*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are ready to write your fi rst CUDA C code. To write a CUDA C program, we need to:\n",
    "1. Create a source code fi le with the special fi le name extension of .cu. \n",
    "2. Compile the program using the CUDA nvcc compiler.\n",
    "3. Run the executable file from the command line, which contains the kernel code executable on the GPU.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting hello_world_gpu.cu\n"
     ]
    }
   ],
   "source": [
    "%%file hello_world_gpu.cu \n",
    "#include <stdio.h>\n",
    "\n",
    "// The qualifier __global__ tells the compiler that the function will be called \n",
    "// from the CPU and executed on the GPU.\n",
    "\n",
    "__global__ void helloFromGPU(void)\n",
    "{\n",
    "    printf(\".............Hello World from GPU!.............\\n\");\n",
    "}\n",
    "\n",
    "int main(void){\n",
    "    // hello from cpu\n",
    "    printf(\"<------------Hello World from CPU!-------------->\\n\");\n",
    "    \n",
    "    // Launch the kernel\n",
    "    // The parameters within the triple angle brackets are the execution configuration, \n",
    "    // which specifi es how many threads will execute the kernel. In this example, we will run 10 GPU threads.\n",
    "    helloFromGPU <<<1, 10>>>();\n",
    "    \n",
    "    \n",
    "    // explicitly destroy and clean up all resources associated with the current\n",
    "    // device in the current process\n",
    "    cudaDeviceReset();\n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<------------Hello World from CPU!-------------->\n",
      ".............Hello World from GPU!.............\n",
      ".............Hello World from GPU!.............\n",
      ".............Hello World from GPU!.............\n",
      ".............Hello World from GPU!.............\n",
      ".............Hello World from GPU!.............\n",
      ".............Hello World from GPU!.............\n",
      ".............Hello World from GPU!.............\n",
      ".............Hello World from GPU!.............\n",
      ".............Hello World from GPU!.............\n",
      ".............Hello World from GPU!.............\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "nvcc hello_world_gpu.cu -o hello_world_gpu\n",
    "./hello_world_gpu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CUDA PROGRAM STRUCTURE \n",
    "\n",
    "A typical CUDA program structure consists of five main steps: \n",
    "1. Allocate GPU memories. \n",
    "2. Copy data from CPU memory to GPU memory. \n",
    "3. Invoke the CUDA kernel to perform program-specifi c computation. \n",
    "4. Copy data back from GPU memory to CPU memory. \n",
    "5. Destroy GPU memories.\n",
    "\n",
    "In the simple program `hello_world_gpu.cu`, you only see the third step: Invoke the kernel. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Remove the [cudaDeviceReset function](https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__DEVICE.html#group__CUDART__DEVICE_1gef69dd5c6d0206c2b8d099abac61f217)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting hello_world_gpu.cu\n"
     ]
    }
   ],
   "source": [
    "%%file hello_world_gpu.cu \n",
    "#include <stdio.h>\n",
    "\n",
    "__global__ void helloFromGPU(void)\n",
    "{\n",
    "    printf(\".............Hello World from GPU!.............\\n\");\n",
    "}\n",
    "\n",
    "int main(void){\n",
    "    // hello from cpu\n",
    "    printf(\"<------------Hello World from CPU!-------------->\\n\");\n",
    "    \n",
    "    helloFromGPU <<<1, 10>>>();\n",
    "    // explicitly destroy and clean up all resources associated with the current\n",
    "    // device in the current process\n",
    "    //cudaDeviceReset();\n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<------------Hello World from CPU!-------------->\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "nvcc hello_world_gpu.cu -o hello_world_gpu\n",
    "./hello_world_gpu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Replace the function `cudaDeviceRest` with `cudaDeviceSynchronize`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting hello_world_gpu.cu\n"
     ]
    }
   ],
   "source": [
    "%%file hello_world_gpu.cu \n",
    "#include <stdio.h>\n",
    "\n",
    "__global__ void helloFromGPU(void)\n",
    "{\n",
    "    printf(\".............Hello World from GPU!.............\\n\");\n",
    "}\n",
    "\n",
    "int main(void){\n",
    "    // hello from cpu\n",
    "    printf(\"<------------Hello World from CPU!-------------->\\n\");\n",
    "    \n",
    "    helloFromGPU <<<1, 10>>>();\n",
    "   \n",
    "    cudaDeviceSynchronize();\n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<------------Hello World from CPU!-------------->\n",
      ".............Hello World from GPU!.............\n",
      ".............Hello World from GPU!.............\n",
      ".............Hello World from GPU!.............\n",
      ".............Hello World from GPU!.............\n",
      ".............Hello World from GPU!.............\n",
      ".............Hello World from GPU!.............\n",
      ".............Hello World from GPU!.............\n",
      ".............Hello World from GPU!.............\n",
      ".............Hello World from GPU!.............\n",
      ".............Hello World from GPU!.............\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "nvcc hello_world_gpu.cu -o hello_world_gpu\n",
    "./hello_world_gpu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Each thread that executes the kernel is given a unique thread ID that is accessible within the kernel through the built-in `threadIdx.x` variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting hello_world_gpu.cu\n"
     ]
    }
   ],
   "source": [
    "%%file hello_world_gpu.cu \n",
    "#include <stdio.h>\n",
    "\n",
    "__global__ void helloFromGPU(void)\n",
    "{   \n",
    "    if (threadIdx.x == 5)\n",
    "        printf(\".............Hello World from GPU thread %d!.............\\n\", threadIdx.x);\n",
    "}\n",
    "\n",
    "int main(void){\n",
    "    // hello from cpu\n",
    "    printf(\"<------------Hello World from CPU!-------------->\\n\");\n",
    "    \n",
    "    helloFromGPU <<<1, 10>>>();\n",
    "   \n",
    "    cudaDeviceSynchronize();\n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<------------Hello World from CPU!-------------->\n",
      ".............Hello World from GPU thread 5!.............\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "nvcc hello_world_gpu.cu -o hello_world_gpu\n",
    "./hello_world_gpu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IS CUDA C PROGRAMMING DIFFICULT?\n",
    "\n",
    "The main difference between CPU programming and GPU programming is the level of programmer exposure to GPU architectural features. Thinking in parallel and having a basic understanding of GPU architecture enables you to write parallel programs that scale to hundreds of cores as easily as you write a sequential program.\n",
    "\n",
    "\n",
    "If you want to write efficient code as a parallel programmer, you need a basic knowledge of CPU architectures. For example, **locality** is a very important concept in parallel programming. \n",
    "- **Locality** refers to the reuse of data so as to reduce memory access latency. \n",
    "\n",
    "There are two basic types of reference locality:\n",
    "\n",
    "- Temporal locality refers to the reuse of data and/or resources within relatively small time durations.\n",
    "- Spatial locality refers to the use of data elements within relatively close storage locations. \n",
    "\n",
    "Modern CPU architectures use large caches to optimize for applications with good spatial and temporal locality. It is the programmer’s responsibility to design their algorithm to effi ciently use CPU cache. Programmers must handle low-level cache optimizations, but have no introspection into how threads are being scheduled on the underlying architecture because the CPU does not expose that information.\n",
    "CUDA exposes you to the concepts of both memory hierarchy and thread hierarchy, extending your ability to control thread execution and scheduling to a greater degree, using: \n",
    "- ➤ Memory hierarchy structure\n",
    "- ➤ Thread hierarchy structure\n",
    "\n",
    "For example, a special memory, called shared memory, is exposed by the CUDA programming model. Shared memory can be thought of as a software-managed cache, which provides great speed-up by conserving bandwidth to main memory. With shared memory, you can control the locality of your code directly.\n",
    "\n",
    "CUDA abstracts away the hardware details and does not require applications to be mapped to traditional graphics APIs. \n",
    "At its core are three key abstractions: \n",
    "- a hierarchy of thread groups, \n",
    "- a hierarchy of memory groups, \n",
    "- and barrier synchronization, \n",
    "\n",
    "which are exposed to us as a minimal set of language extensions. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
