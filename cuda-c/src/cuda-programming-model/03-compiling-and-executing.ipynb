{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting sumArraysOnGPU.cu\n"
     ]
    }
   ],
   "source": [
    "%%file sumArraysOnGPU.cu\n",
    "\n",
    "#include <stdlib.h>\n",
    "#include <string.h>\n",
    "#include <time.h>\n",
    "#include <stdio.h>\n",
    "#include <cuda_runtime.h>\n",
    "\n",
    "\n",
    "#define CHECK(call)                                                            \\\n",
    "{                                                                              \\\n",
    "    const cudaError_t error = call;                                            \\\n",
    "    if (error != cudaSuccess)                                                  \\\n",
    "    {                                                                          \\\n",
    "        fprintf(stderr, \"Error: %s:%d, \", __FILE__, __LINE__);                 \\\n",
    "        fprintf(stderr, \"code: %d, reason: %s\\n\", error,                       \\\n",
    "                cudaGetErrorString(error));                                    \\\n",
    "        exit(1);                                                               \\\n",
    "    }                                                                          \\\n",
    "}\n",
    "\n",
    "\n",
    "__global__ void sumArraysOnDevice(float *A, float *B, float *C){\n",
    "    int idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "    C[idx] = A[idx] + B[idx];\n",
    "\n",
    "}\n",
    "\n",
    "\n",
    "void initialData(float *ip, int size){\n",
    "    // generate different seed for random number \n",
    "    time_t t;\n",
    "    srand((unsigned int) time (&t));\n",
    "    \n",
    "    for (int i=0; i<size; i++){\n",
    "        ip[i] = (float)(rand() & 0xFF) / 10.0f;\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "void sumArraysOnHost(float *A, float *B, float *C, const int N){\n",
    "    for (int idx=0; idx<N; idx++){\n",
    "        C[idx] = A[idx] + B[idx];\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "void checkResult(float *hostRef, float *gpuRef, const int N){\n",
    "    double epsilon = 1.0E-8;\n",
    "    int match = 1;\n",
    "    for (int i = 0; i < N; i++){\n",
    "        if (abs(hostRef[i] - gpuRef[i]) > epsilon){\n",
    "            match = 0;\n",
    "            printf(\"Arrays do not match!\\n\");\n",
    "            printf(\"host %5.2f gpu %5.2f at current %d\\n\",\n",
    "                   hostRef[i], gpuRef[i], i);\n",
    "            break;\n",
    "        }\n",
    "    }\n",
    "    if (match) printf(\"Arrays match. \\n\\n\");\n",
    "}\n",
    "\n",
    "\n",
    "int main(int argc, char **argv){\n",
    "    \n",
    "    printf(\"%s Starting...\\n\", argv[0]);\n",
    "    \n",
    "    // malloc host memory\n",
    "    int nElem = 10000;\n",
    "    size_t nBytes = nElem * sizeof(float);\n",
    "    \n",
    "    \n",
    "    // initialize data at host side\n",
    "    float *h_A, *h_B, *hostRef, *gpuRef;\n",
    "    h_A = (float *)malloc(nBytes);\n",
    "    h_B = (float *)malloc(nBytes);\n",
    "    hostRef = (float *)malloc(nBytes);\n",
    "    gpuRef = (float *)malloc(nBytes);\n",
    "    \n",
    "    // initialize data at host side\n",
    "    initialData(h_A, nElem);\n",
    "    initialData(h_B, nElem);\n",
    "    \n",
    "    memset(hostRef, 0, nBytes);\n",
    "    memset(gpuRef, 0, nBytes);\n",
    "    \n",
    "    // malloc device global memory \n",
    "    float *d_A, *d_B, *d_C;\n",
    "    cudaMalloc((float**)&d_A, nBytes);\n",
    "    cudaMalloc((float**)&d_B, nBytes);\n",
    "    cudaMalloc((float**)&d_C, nBytes);\n",
    "    \n",
    "    // Use cudaMemcpy to transfer the data from the host memory to the GPU global memory with the\n",
    "    // parameter cudaMemcpyHostToDevice specifying the transfer direction.\n",
    "    \n",
    "    CHECK(cudaMemcpy(d_A, h_A, nBytes, cudaMemcpyHostToDevice));\n",
    "    CHECK(cudaMemcpy(d_B, h_B, nBytes, cudaMemcpyHostToDevice));\n",
    "    \n",
    "    // invoke kernel at host side\n",
    "    dim3 block(100);\n",
    "    dim3 grid(nElem / block.x);\n",
    "    \n",
    "    sumArraysOnDevice<<<grid, block>>>(d_A, d_B, d_C);\n",
    "    printf(\"Execution configuration <<<%d, %d>>>\\n\", grid.x, block.x);\n",
    "    \n",
    "    // copy kernel result back to host side \n",
    "    cudaMemcpy(gpuRef, d_C, nBytes, cudaMemcpyDeviceToHost);\n",
    "    \n",
    "    // add vector at host side for result checks\n",
    "    sumArraysOnHost(h_A, h_B, hostRef, nElem);\n",
    "    \n",
    "    for (int i=0; i<10; i++){\n",
    "         printf(\"%f + %f = %f \\n\", h_A[i], h_B[i], hostRef[i]);\n",
    "\n",
    "    }\n",
    "    \n",
    "    // check device results\n",
    "    checkResult(hostRef, gpuRef, nElem);\n",
    "    \n",
    "    free(h_A);\n",
    "    free(h_B);\n",
    "    free(hostRef);\n",
    "    free(gpuRef);\n",
    "    \n",
    "    // use cudaFree to release the memory used on the GPU\n",
    "    cudaFree(d_A);\n",
    "    cudaFree(d_B);\n",
    "    cudaFree(d_C);\n",
    "    cudaDeviceReset();\n",
    "    \n",
    "    return (0);\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./addvector Starting...\n",
      "Execution configuration <<<100, 100>>>\n",
      "17.600000 + 17.600000 = 35.200001 \n",
      "16.299999 + 16.299999 = 32.599998 \n",
      "0.600000 + 0.600000 = 1.200000 \n",
      "23.200001 + 23.200001 = 46.400002 \n",
      "16.799999 + 16.799999 = 33.599998 \n",
      "15.600000 + 15.600000 = 31.200001 \n",
      "2.200000 + 2.200000 = 4.400000 \n",
      "19.700001 + 19.700001 = 39.400002 \n",
      "4.300000 + 4.300000 = 8.600000 \n",
      "3.200000 + 3.200000 = 6.400000 \n",
      "Arrays match. \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "==26284== NVPROF is profiling process 26284, command: ./addvector\n",
      "==26284== Profiling application: ./addvector\n",
      "==26284== Profiling result:\n",
      "            Type  Time(%)      Time     Calls       Avg       Min       Max  Name\n",
      " GPU activities:   61.39%  41.056us         2  20.528us  19.840us  21.216us  [CUDA memcpy HtoD]\n",
      "                   32.87%  21.984us         1  21.984us  21.984us  21.984us  [CUDA memcpy DtoH]\n",
      "                    5.74%  3.8400us         1  3.8400us  3.8400us  3.8400us  sumArraysOnDevice(float*, float*, float*)\n",
      "      API calls:   67.64%  108.27ms         3  36.090ms  6.2490us  108.25ms  cudaMalloc\n",
      "                   31.70%  50.742ms         1  50.742ms  50.742ms  50.742ms  cudaDeviceReset\n",
      "                    0.37%  586.92us        94  6.2430us     177ns  259.83us  cuDeviceGetAttribute\n",
      "                    0.10%  166.18us         3  55.392us  6.7450us  147.89us  cudaFree\n",
      "                    0.07%  117.21us         3  39.069us  22.571us  54.160us  cudaMemcpy\n",
      "                    0.05%  80.415us         1  80.415us  80.415us  80.415us  cuDeviceTotalMem\n",
      "                    0.05%  75.864us         1  75.864us  75.864us  75.864us  cuDeviceGetName\n",
      "                    0.02%  25.566us         1  25.566us  25.566us  25.566us  cudaLaunch\n",
      "                    0.00%  2.8060us         2  1.4030us  1.2850us  1.5210us  cuDeviceGetCount\n",
      "                    0.00%  2.7890us         3     929ns     221ns  2.1490us  cudaSetupArgument\n",
      "                    0.00%  1.0910us         2     545ns     450ns     641ns  cuDeviceGet\n",
      "                    0.00%     788ns         1     788ns     788ns     788ns  cudaConfigureCall\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "nvcc sumArraysOnGPU.cu -o addvector\n",
    "nvprof --unified-memory-profiling off ./addvector\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
