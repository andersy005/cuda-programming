{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting sumArraysOnGPU.cu\n"
     ]
    }
   ],
   "source": [
    "%%file sumArraysOnGPU.cu\n",
    "\n",
    "#include <stdlib.h>\n",
    "#include <string.h>\n",
    "#include <time.h>\n",
    "#include <stdio.h>\n",
    "#include <cuda_runtime.h>\n",
    "#include <sys/time.h>\n",
    "\n",
    "double cpuSecond(){\n",
    "    struct timeval tp;\n",
    "    gettimeofday(&tp, NULL);\n",
    "    return ((double)tp.tv_sec + (double)tp.tv_usec*1.e-6);\n",
    "}\n",
    "\n",
    "#define CHECK(call)                                                            \\\n",
    "{                                                                              \\\n",
    "    const cudaError_t error = call;                                            \\\n",
    "    if (error != cudaSuccess)                                                  \\\n",
    "    {                                                                          \\\n",
    "        fprintf(stderr, \"Error: %s:%d, \", __FILE__, __LINE__);                 \\\n",
    "        fprintf(stderr, \"code: %d, reason: %s\\n\", error,                       \\\n",
    "                cudaGetErrorString(error));                                    \\\n",
    "        exit(1);                                                               \\\n",
    "    }                                                                          \\\n",
    "}\n",
    "\n",
    "\n",
    "__global__ void sumArraysOnDevice(float *A, float *B, float *C, const int N){\n",
    "    int idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "    if (idx < N) C[idx] = A[idx] + B[idx];\n",
    "\n",
    "}\n",
    "\n",
    "\n",
    "void initialData(float *ip, int size){\n",
    "    // generate different seed for random number \n",
    "    time_t t;\n",
    "    srand((unsigned int) time (&t));\n",
    "    \n",
    "    for (int i=0; i<size; i++){\n",
    "        ip[i] = (float)(rand() & 0xFF) / 10.0f;\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "void sumArraysOnHost(float *A, float *B, float *C, const int N){\n",
    "    for (int idx=0; idx<N; idx++){\n",
    "        C[idx] = A[idx] + B[idx];\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "void checkResult(float *hostRef, float *gpuRef, const int N){\n",
    "    double epsilon = 1.0E-8;\n",
    "    int match = 1;\n",
    "    for (int i = 0; i < N; i++){\n",
    "        if (abs(hostRef[i] - gpuRef[i]) > epsilon){\n",
    "            match = 0;\n",
    "            printf(\"Arrays do not match!\\n\");\n",
    "            printf(\"host %5.2f gpu %5.2f at current %d\\n\",\n",
    "                   hostRef[i], gpuRef[i], i);\n",
    "            break;\n",
    "        }\n",
    "    }\n",
    "    if (match) printf(\"Arrays match. \\n\\n\");\n",
    "}\n",
    "\n",
    "\n",
    "int main(int argc, char **argv){\n",
    "    \n",
    "    printf(\"%s Starting...\\n\", argv[0]);\n",
    "    \n",
    "    // malloc host memory\n",
    "    int nElem = 1 <<24;\n",
    "    size_t nBytes = nElem * sizeof(float);\n",
    "    \n",
    "    \n",
    "    // initialize data at host side\n",
    "    float *h_A, *h_B, *hostRef, *gpuRef;\n",
    "    h_A = (float *)malloc(nBytes);\n",
    "    h_B = (float *)malloc(nBytes);\n",
    "    hostRef = (float *)malloc(nBytes);\n",
    "    gpuRef = (float *)malloc(nBytes);\n",
    "    \n",
    "    // initialize data at host side\n",
    "    initialData(h_A, nElem);\n",
    "    initialData(h_B, nElem);\n",
    "    \n",
    "    memset(hostRef, 0, nBytes);\n",
    "    memset(gpuRef, 0, nBytes);\n",
    "    \n",
    "    // malloc device global memory \n",
    "    float *d_A, *d_B, *d_C;\n",
    "    cudaMalloc((float**)&d_A, nBytes);\n",
    "    cudaMalloc((float**)&d_B, nBytes);\n",
    "    cudaMalloc((float**)&d_C, nBytes);\n",
    "    \n",
    "    // Use cudaMemcpy to transfer the data from the host memory to the GPU global memory with the\n",
    "    // parameter cudaMemcpyHostToDevice specifying the transfer direction.\n",
    "    \n",
    "    CHECK(cudaMemcpy(d_A, h_A, nBytes, cudaMemcpyHostToDevice));\n",
    "    CHECK(cudaMemcpy(d_B, h_B, nBytes, cudaMemcpyHostToDevice));\n",
    "    \n",
    "    // invoke kernel at host side\n",
    "    int iLen = 128;\n",
    "    dim3 block(iLen);\n",
    "    dim3 grid((nElem+block.x-1)/block.x);\n",
    "    \n",
    "    double iStart = cpuSecond();\n",
    "    sumArraysOnDevice<<<grid, block>>>(d_A, d_B, d_C, nElem);\n",
    "    CHECK(cudaDeviceSynchronize());\n",
    "    double iElaps = cpuSecond() - iStart;\n",
    "    printf(\"sumArraysOnGPU <<<%d,%d>>> Time elapsed %f sec\\n\", grid.x, block.x, iElaps);\n",
    "    //printf(\"Execution configuration <<<%d, %d>>>\\n\", grid.x, block.x);\n",
    "    \n",
    "    // copy kernel result back to host side \n",
    "    cudaMemcpy(gpuRef, d_C, nBytes, cudaMemcpyDeviceToHost);\n",
    "    \n",
    "    // add vector at host side for result checks\n",
    "    sumArraysOnHost(h_A, h_B, hostRef, nElem);\n",
    "    \n",
    "    for (int i=0; i<10; i++){\n",
    "         printf(\"%f + %f = %f \\n\", h_A[i], h_B[i], hostRef[i]);\n",
    "\n",
    "    }\n",
    "    \n",
    "    // check device results\n",
    "    checkResult(hostRef, gpuRef, nElem);\n",
    "    \n",
    "    free(h_A);\n",
    "    free(h_B);\n",
    "    free(hostRef);\n",
    "    free(gpuRef);\n",
    "    \n",
    "    // use cudaFree to release the memory used on the GPU\n",
    "    cudaFree(d_A);\n",
    "    cudaFree(d_B);\n",
    "    cudaFree(d_C);\n",
    "    cudaDeviceReset();\n",
    "    \n",
    "    return (0);\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./addvector Starting...\n",
      "sumArraysOnGPU <<<131072,128>>> Time elapsed 0.016467 sec\n",
      "2.800000 + 2.800000 = 5.600000 \n",
      "10.000000 + 10.000000 = 20.000000 \n",
      "2.600000 + 2.600000 = 5.200000 \n",
      "22.299999 + 22.299999 = 44.599998 \n",
      "11.000000 + 11.000000 = 22.000000 \n",
      "9.900000 + 9.900000 = 19.799999 \n",
      "14.600000 + 14.600000 = 29.200001 \n",
      "22.299999 + 22.299999 = 44.599998 \n",
      "21.100000 + 21.100000 = 42.200001 \n",
      "8.600000 + 8.600000 = 17.200001 \n",
      "Arrays match. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "nvcc sumArraysOnGPU.cu -o addvector\n",
    "./addvector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Timing with nvprof"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./addvector Starting...\n",
      "==19639== NVPROF is profiling process 19639, command: ./addvector\n",
      "sumArraysOnGPU <<<131072,128>>> Time elapsed 0.014515 sec\n",
      "24.600000 + 24.600000 = 49.200001 \n",
      "11.400000 + 11.400000 = 22.799999 \n",
      "9.800000 + 9.800000 = 19.600000 \n",
      "15.000000 + 15.000000 = 30.000000 \n",
      "0.800000 + 0.800000 = 1.600000 \n",
      "22.700001 + 22.700001 = 45.400002 \n",
      "8.800000 + 8.800000 = 17.600000 \n",
      "17.700001 + 17.700001 = 35.400002 \n",
      "5.100000 + 5.100000 = 10.200000 \n",
      "3.800000 + 3.800000 = 7.600000 \n",
      "Arrays match. \n",
      "\n",
      "==19639== Profiling application: ./addvector\n",
      "==19639== Profiling result:\n",
      "            Type  Time(%)      Time     Calls       Avg       Min       Max  Name\n",
      " GPU activities:   61.59%  86.326ms         2  43.163ms  43.142ms  43.184ms  [CUDA memcpy HtoD]\n",
      "                   28.89%  40.487ms         1  40.487ms  40.487ms  40.487ms  [CUDA memcpy DtoH]\n",
      "                    9.52%  13.347ms         1  13.347ms  13.347ms  13.347ms  sumArraysOnDevice(float*, float*, float*, int)\n",
      "      API calls:   40.42%  166.13ms         3  55.378ms  263.99us  165.59ms  cudaMalloc\n",
      "                   30.71%  126.23ms         3  42.076ms  40.685ms  43.332ms  cudaMemcpy\n",
      "                   16.15%  66.370ms         1  66.370ms  66.370ms  66.370ms  cudaDeviceReset\n",
      "                    8.37%  34.394ms         3  11.465ms  364.77us  26.767ms  cudaFree\n",
      "                    3.52%  14.469ms         1  14.469ms  14.469ms  14.469ms  cudaDeviceSynchronize\n",
      "                    0.65%  2.6564ms        94  28.259us     256ns  1.1985ms  cuDeviceGetAttribute\n",
      "                    0.10%  402.69us         1  402.69us  402.69us  402.69us  cuDeviceGetName\n",
      "                    0.07%  279.80us         1  279.80us  279.80us  279.80us  cuDeviceTotalMem\n",
      "                    0.01%  35.872us         1  35.872us  35.872us  35.872us  cudaLaunch\n",
      "                    0.00%  3.0730us         4     768ns     181ns  2.1630us  cudaSetupArgument\n",
      "                    0.00%  2.3970us         2  1.1980us     572ns  1.8250us  cuDeviceGetCount\n",
      "                    0.00%  1.6430us         1  1.6430us  1.6430us  1.6430us  cudaConfigureCall\n",
      "                    0.00%  1.0380us         2     519ns     269ns     769ns  cuDeviceGet\n"
     ]
    }
   ],
   "source": [
    "!nvprof --unified-memory-profiling off ./addvector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usage: nvprof [options] [application] [application-arguments]\r\n",
      "Options:\r\n",
      "       --aggregate-mode <on|off>\r\n",
      "                        Turn on/off aggregate mode for events and metrics specified\r\n",
      "                        by subsequent \"--events\" and \"--metrics\" options. Those\r\n",
      "                        event/metric values will be collected for each domain instance,\r\n",
      "                        instead of the whole device. Allowed values:\r\n",
      "                        \ton - turn on aggregate mode (default)\r\n",
      "                        \toff - turn off aggregate mode\r\n",
      "\r\n",
      "       --analysis-metrics\r\n",
      "                        Collect profiling data that can be imported to Visual Profiler's\r\n",
      "                        \"analysis\" mode. Note: Use \"--export-profile\" to specify\r\n",
      "                        an export file.\r\n",
      "\r\n",
      "       --annotate-mpi <off|openmpi|mpich>\r\n",
      "                        Automatically annotate MPI calls with NVTX markers. Specify\r\n",
      "                        the MPI implementation installed on your machine. Currently,\r\n",
      "                        Open MPI and MPICH implementations are supported. By default,\r\n",
      "                        this option is off.\r\n",
      "\r\n",
      "       --concurrent-kernels <on|off>\r\n",
      "                        Turn on/off concurrent kernel execution. If concurrent kernel\r\n",
      "                        execution is off, all kernels running on one device will\r\n",
      "                        be serialized. Allowed values:\r\n",
      "                        \ton - turn on concurrent kernel execution (default)\r\n",
      "                        \toff - turn off concurrent kernel execution\r\n",
      "\r\n",
      "       --continuous-sampling-interval <interval>\r\n",
      "                        Set the continuous mode sampling interval in milliseconds.\r\n",
      "                        Minimum is 1 ms. Default is 2 ms.\r\n",
      "\r\n",
      "       --cpu-thread-tracing <on|off>\r\n",
      "                        Collect information about CPU thread API activity.\r\n",
      "                        Allowed values:\r\n",
      "                        \ton  - turn on CPU thread API tracing\r\n",
      "                        \toff - turn off CPU thread API tracing (default)\r\n",
      "\r\n",
      "       --dependency-analysis\r\n",
      "                        Generate event dependency graph for host and device activities\r\n",
      "                        and run dependency analysis.\r\n",
      "\r\n",
      "       --device-buffer-size <size in MBs>\r\n",
      "                        Set the device memory size (in MBs) reserved for storing\r\n",
      "                        profiling data for non-CDP operations, especially for concurrent\r\n",
      "                        kernel tracing, for each buffer on a context. The default\r\n",
      "                        value is 8MB. The size should be a positive integer.\r\n",
      "\r\n",
      "       --device-cdp-buffer-size <size in MBs>\r\n",
      "                        Set the device memory size (in MBs) reserved for storing\r\n",
      "                        profiling data for CDP operations for each buffer on a context.\r\n",
      "                        The default value is 8MB. The size should be a positive\r\n",
      "                        integer.\r\n",
      "\r\n",
      "       --devices <device ids>\r\n",
      "                        Change the scope of subsequent \"--events\", \"--metrics\", \"--query-events\"\r\n",
      "                        and \"--query-metrics\" options.\r\n",
      "                        Allowed values:\r\n",
      "                        \tall - change scope to all valid devices\r\n",
      "                        \tcomma-separated device IDs - change scope to specified\r\n",
      "                        devices\r\n",
      "\r\n",
      "       --event-collection-mode <mode>\r\n",
      "                        Choose event collection mode for all events/metrics Allowed\r\n",
      "                        values:\r\n",
      "                        \tkernel - events/metrics are collected only for durations\r\n",
      "                        of kernel executions (default)\r\n",
      "                        \tcontinuous - events/metrics are collected for duration\r\n",
      "                        of application. This is not applicable for non-tesla devices.\r\n",
      "                        This mode is compatible only with NVLink events/metrics.\r\n",
      "                        This modeis incompatible with \"--profile-all-processes\"\r\n",
      "                        or \"--profile-child-processes\" or \"--replay-mode kernel\"\r\n",
      "                        or \"--replay-mode application\".\r\n",
      "\r\n",
      "  -e,  --events <event names>\r\n",
      "                        Specify the events to be profiled on certain device(s). Multiple\r\n",
      "                        event names separated by comma can be specified. Which device(s)\r\n",
      "                        are profiled is controlled by the \"--devices\" option. Otherwise\r\n",
      "                        events will be collected on all devices.\r\n",
      "                        For a list of available events, use \"--query-events\".\r\n",
      "                        Use \"--events all\" to profile all events available for each\r\n",
      "                        device.\r\n",
      "                        Use \"--devices\" and \"--kernels\" to select a specific kernel\r\n",
      "                        invocation.\r\n",
      "\r\n",
      "       --kernel-latency-timestamps <on|off>\r\n",
      "                        Turn on/off collection of kernel latency timestamps, namely\r\n",
      "                        queued and submitted. The queued timestamp is captured when\r\n",
      "                        a kernel launch command was queued into the CPU command\r\n",
      "                        buffer. The submitted timestamp denotes when the CPU command\r\n",
      "                        buffer containing this kernel launch was submitted to the\r\n",
      "                        GPU. Turning this option on may incur an overhead during\r\n",
      "                        profiling. Allowed values:\r\n",
      "                        \ton - turn on collection of kernel latency timestamps\r\n",
      "                        \toff - turn off collection of kernel latency timestamps\r\n",
      "                        (default)\r\n",
      "\r\n",
      "       --kernels <kernel path syntax>\r\n",
      "                        Change the scope of subsequent \"--events\", \"--metrics\" options.\r\n",
      "                        The syntax is as follows:\r\n",
      "                        \t<kernel name>\r\n",
      "                        \tLimit scope to given kernel name.\r\n",
      "                        or\r\n",
      "                        \t<context id/name>:<stream id/name>:<kernel name>:<invocation>\r\n",
      "                        The context/stream IDs, names, kernel name and invocation\r\n",
      "                        can be regular expressions. Empty string matches any number\r\n",
      "                        or characters. If <context id/name> or <stream id/name>\r\n",
      "                        is a positive number, it's strictly matched against the\r\n",
      "                        CUDA context/stream ID. Otherwise it's treated as a regular\r\n",
      "                        expression and matched against the context/stream name specified\r\n",
      "                        by the NVTX library. If the invocation count is a positive\r\n",
      "                        number, it's strictly matched against the invocation of\r\n",
      "                        the kernel. Otherwise it's treated as a regular expression.\r\n",
      "                        Example: --kernels \"1:foo:bar:2\" will profile any kernel\r\n",
      "                        whose name contains \"bar\" and is the 2nd instance on context\r\n",
      "                        1 and on stream named \"foo\".\r\n",
      "\r\n",
      "  -m,  --metrics <metric names>\r\n",
      "                        Specify the metrics to be profiled on certain device(s).\r\n",
      "                        Multiple metric names separated by comma can be specified.\r\n",
      "                        Which device(s) are profiled is controlled by the \"--devices\"\r\n",
      "                        option. Otherwise metrics will be collected on all devices.\r\n",
      "                        For a list of available metrics, use \"--query-metrics\".\r\n",
      "                        Use \"--metrics all\" to profile all metrics available for\r\n",
      "                        each device.\r\n",
      "                        Use \"--devices\" and \"--kernels\" to select a specific kernel\r\n",
      "                        invocation. \r\n",
      "                        Note: \"--metrics all\" does not include some metrics which\r\n",
      "                        are needed for Visual Profiler's source level analysis.\r\n",
      "                        For that, use \"--analysis-metrics\".\r\n",
      "\r\n",
      "       --pc-sampling-period <period>\r\n",
      "                        Specify PC Sampling period in cycles,  at which the sampling\r\n",
      "                        records will be dumped. Allowed values for the period are\r\n",
      "                        integers between 5 to 31 both inclusive.\r\n",
      "                        This will set the sampling period to (2^period) cycles\r\n",
      "                        Default value is a number between 5 and 12 based on the setup.Note:\r\n",
      "                        Only available for GM20X+.\r\n",
      "                        \r\n",
      "\r\n",
      "       --profile-all-processes\r\n",
      "                        Profile all processes launched by the same user who launched\r\n",
      "                        this nvprof instance. Note: Only one instance of nvprof\r\n",
      "                        can run with this option at the same time. Under this mode,\r\n",
      "                        there's no need to specify an application to run.\r\n",
      "\r\n",
      "       --profile-api-trace <none|runtime|driver|all>\r\n",
      "                        Turn on/off CUDA runtime/driver API tracing. Allowed values:\r\n",
      "                        \tnone - turn off API tracing\r\n",
      "                        \truntime - only turn on CUDA runtime API tracing\r\n",
      "                        \tdriver - only turn on CUDA driver API tracing\r\n",
      "                        \tall - turn on all API tracing (default)\r\n",
      "\r\n",
      "       --profile-child-processes\r\n",
      "                        Profile the application and all child processes launched\r\n",
      "                        by it.\r\n",
      "\r\n",
      "       --profile-from-start <on|off>\r\n",
      "                        Enable/disable profiling from the start of the application.\r\n",
      "                        If it's disabled, the application can use {cu,cuda}Profiler{Start,Stop}\r\n",
      "                        to turn on/off profiling. Allowed values:\r\n",
      "                        \ton - enable profiling from start (default)\r\n",
      "                        \toff - disable profiling from start\r\n",
      "\r\n",
      "       --profiling-semaphore-pool-size <count>\r\n",
      "                        Set the profiling semaphore pool size reserved for storing\r\n",
      "                        profiling data for serialized kernels and memory operations\r\n",
      "                        for each context. The default value is 65536. The size should\r\n",
      "                        be a positive integer.\r\n",
      "\r\n",
      "       --query-events\r\n",
      "                        List all the events available on the device(s). Device(s)\r\n",
      "                        queried can be controlled by the \"--devices\" option.\r\n",
      "\r\n",
      "       --query-metrics\r\n",
      "                        List all the metrics available on the device(s). Device(s)\r\n",
      "                        queried can be controlled by the \"--devices\" option.\r\n",
      "\r\n",
      "       --replay-mode <mode>\r\n",
      "                        Choose replay mode used when not all events/metrics can be\r\n",
      "                        collected in a single run. Allowed values:\r\n",
      "                        \tdisabled - replay is disabled, events/metrics couldn't\r\n",
      "                        be profiled will be dropped\r\n",
      "                        \tkernel - each kernel invocation is replayed (default)\r\n",
      "                        \tapplication - the entire application is replayed.\r\n",
      "                        This modeis incompatible with \"--profile-all-processes\"\r\n",
      "                        or \"profile-child-processes\".\r\n",
      "\r\n",
      "  -a,  --source-level-analysis <source level analysis names>\r\n",
      "                        Specify the source level metrics to be profiled on a certain\r\n",
      "                        kernel invocation. Use \"--devices\" and \"--kernels\" to select\r\n",
      "                        a specific kernel invocation. Allowed values: one or more\r\n",
      "                        of the following, separated by commas\r\n",
      "                        \tglobal_access: global access\r\n",
      "                        \tshared_access: shared access\r\n",
      "                        \tbranch: divergent branch\r\n",
      "                        \tinstruction_execution: instruction execution\r\n",
      "                        \tpc_sampling: pc sampling, available only for GM20X+\r\n",
      "                        Note: Use \"--export-profile\" to specify an export file.\r\n",
      "\r\n",
      "       --system-profiling <on|off>\r\n",
      "                        Turn on/off power, clock, and thermal profiling. Allowed\r\n",
      "                        values:\r\n",
      "                        \ton - turn on system profiling\r\n",
      "                        \toff - turn off system profiling (default)\r\n",
      "\r\n",
      "  -t,  --timeout <seconds>\r\n",
      "                        Set an execution timeout (in seconds) for the CUDA application.\r\n",
      "                        Note: Timeout starts counting from the moment the CUDA driver\r\n",
      "                        is initialized. If the application doesn't call any CUDA\r\n",
      "                        APIs, timeout won't be triggered.\r\n",
      "\r\n",
      "       --track-memory-allocations <on|off>\r\n",
      "                        Turn on/off tracking of memory operations, which involves\r\n",
      "                        recording timestamps, memory size, memory type and program\r\n",
      "                        counters of the memory allocations and frees. Turning this\r\n",
      "                        option on may incur an overhead during profiling. Allowed\r\n",
      "                        values:\r\n",
      "                        \ton - turn on tracking of memory allocations and\r\n",
      "                        free\r\n",
      "                        \toff - turn off tracking of memory allocations and\r\n",
      "                        free (default)\r\n",
      "\r\n",
      "       --unified-memory-profiling <per-process-device|off>\r\n",
      "                        Configure unified memory profiling. Allowed values:\r\n",
      "                        \tper-process-device - collect counts for each process\r\n",
      "                        and each device (default)\r\n",
      "                        \toff - turn off unified memory profiling\r\n",
      "\r\n",
      "       --cpu-profiling <on|off>\r\n",
      "                        Turn on CPU profiling. Note: CPU profiling is not supported\r\n",
      "                        in multi-process mode.\r\n",
      "\r\n",
      "       --cpu-profiling-explain-ccff <filename>\r\n",
      "                        Path to a PGI pgexplain.xml file that should be used to interpret\r\n",
      "                        Common Compiler Feedback Format (CCFF) messages.\r\n",
      "\r\n",
      "       --cpu-profiling-frequency <frequency>\r\n",
      "                        Set the CPU profiling frequency in samples per second. Default\r\n",
      "                        is 100Hz. Maximum is 500Hz.\r\n",
      "\r\n",
      "       --cpu-profiling-max-depth <depth>\r\n",
      "                        Set the maximum depth of each call stack. Zero means no limit.\r\n",
      "                        Default is zero.\r\n",
      "\r\n",
      "       --cpu-profiling-mode <flat|top-down|bottom-up>\r\n",
      "                        Set the output mode of CPU profiling. Allowed values:\r\n",
      "                        \tflat - Show flat profile\r\n",
      "                        \ttop-down - Show parent functions at the top\r\n",
      "                        \tbottom-up - Show parent functions at the bottom\r\n",
      "                        (default)\r\n",
      "\r\n",
      "       --cpu-profiling-percentage-threshold <threshold>\r\n",
      "                        Filter out the entries that are below the set percentage\r\n",
      "                        threshold. The limit should be an integer between 0 and\r\n",
      "                        100, inclusive. Zero means no limit. Default is zero.\r\n",
      "\r\n",
      "       --cpu-profiling-scope <function|instruction>\r\n",
      "                        Choose the profiling scope. Allowed values:\r\n",
      "                        \tfunction - Each level in the stack trace represents\r\n",
      "                        a distinct function (default)\r\n",
      "                        \tinstruction - Each level in the stack trace represents\r\n",
      "                        a distinct instruction address\r\n",
      "\r\n",
      "       --cpu-profiling-show-ccff <on|off>\r\n",
      "                        Choose whether to print Common Compiler Feedback Format (CCFF)\r\n",
      "                        messages embedded in the binary. Note: this option implies\r\n",
      "                        \"--cpu-profiling-scope instruction\".Default is off.\r\n",
      "\r\n",
      "       --cpu-profiling-show-library <on|off>\r\n",
      "                        Choose whether to print the library name for each sample.\r\n",
      "\r\n",
      "       --cpu-profiling-thread-mode <separated|aggregated>\r\n",
      "                        Set the thread mode of CPU profiling. Allowed values:\r\n",
      "                        \tseparated - Show separate profile for each thread\r\n",
      "                        \taggregated - Aggregate data from all threads (default)\r\n",
      "\r\n",
      "       --cpu-profiling-unwind-stack <on|off>\r\n",
      "                        Choose whether to unwind the CPU call-stack at each sample\r\n",
      "                        point. Default is on. \r\n",
      "\r\n",
      "       --openacc-profiling <on|off>\r\n",
      "                        Enable/disable recording information from the OpenACC profiling\r\n",
      "                        interface. Note: if the OpenACC profiling interface is available\r\n",
      "                        depends on the OpenACC runtime. Default is on.\r\n",
      "\r\n",
      "       --context-name <name>\r\n",
      "                        Name of the CUDA context.\r\n",
      "                        \t\"%i\" in the context name string is replaced with\r\n",
      "                        the ID of the context.\r\n",
      "                        \t\"%p\" in the context name string is replaced with\r\n",
      "                        the process ID of the application being profiled.\r\n",
      "                        \t\"%q{<ENV>}\" in the context name string is replaced\r\n",
      "                        with the value of the environment variable \"<ENV>\". If the\r\n",
      "                        environment variable is not set it's an error.\r\n",
      "                        \t\"%h\" in the context name string is replaced with\r\n",
      "                        the hostname of the system.\r\n",
      "                        \t\"%%\" in the context name string is replaced with\r\n",
      "                        \"%\". Any other character following \"%\" is illegal.\r\n",
      "\r\n",
      "       --csv\r\n",
      "                        Use comma-separated values in the output.\r\n",
      "\r\n",
      "       --demangling <on|off>\r\n",
      "                        Turn on/off C++ name demangling of function names. Allowed\r\n",
      "                        values:\r\n",
      "                        \ton - turn on demangling (default)\r\n",
      "                        \toff - turn off demangling\r\n",
      "\r\n",
      "  -u,  --normalized-time-unit <s|ms|us|ns|col|auto>\r\n",
      "                        Specify the unit of time that will be used in the output.\r\n",
      "                        Allowed values:\r\n",
      "                        \ts - second, ms - millisecond, us - microsecond,\r\n",
      "                        ns - nanosecond\r\n",
      "                        \tcol - a fixed unit for each column\r\n",
      "                        \tauto (default) - the scale is chosen for each value\r\n",
      "                        based on its length.\r\n",
      "\r\n",
      "       --openacc-summary-mode <mode>\r\n",
      "                        Set how durations are computed in the OpenACC summary. Allowed\r\n",
      "                        values:\r\n",
      "                        \texclusive: show exclusive times (default)\r\n",
      "                        \tinclusive: show inclusive times\r\n",
      "\r\n",
      "       --print-api-summary\r\n",
      "                        Print a summary of CUDA runtime/driver API calls.\r\n",
      "\r\n",
      "       --print-api-trace\r\n",
      "                        Print CUDA runtime/driver API trace.\r\n",
      "\r\n",
      "       --print-dependency-analysis-trace\r\n",
      "                        Print dependency analysis trace.\r\n",
      "\r\n",
      "       --print-gpu-summary\r\n",
      "                        Print a summary of the activities on the GPU (including CUDA\r\n",
      "                        kernels and memcpy's/memset's).\r\n",
      "\r\n",
      "       --print-gpu-trace\r\n",
      "                        Print individual kernel invocations (including CUDA memcpy's/memset's)\r\n",
      "                        and sort them in chronological order. In event/metric profiling\r\n",
      "                        mode, show events/metrics for each kernel invocation.\r\n",
      "\r\n",
      "       --print-openacc-constructs\r\n",
      "                        Include parent construct names in OpenACC profile.\r\n",
      "\r\n",
      "       --print-openacc-summary\r\n",
      "                        Print a summary of the OpenACC profile.\r\n",
      "\r\n",
      "       --print-openacc-trace\r\n",
      "                        Print a trace of the OpenACC profile.\r\n",
      "\r\n",
      "  -s,  --print-summary\r\n",
      "                        Print a summary of the profiling result on screen. Note:\r\n",
      "                        This is the default unless \"--export-profile\" or other print\r\n",
      "                        options are used.\r\n",
      "\r\n",
      "       --print-summary-per-gpu\r\n",
      "                        Print a summary of the profiling result for each GPU.\r\n",
      "\r\n",
      "       --process-name <name>\r\n",
      "                        Name of the process.\r\n",
      "                        \t\"%p\" in the process name string is replaced with\r\n",
      "                        the process ID of the application being profiled.\r\n",
      "                        \t\"%q{<ENV>}\" in the process name string is replaced\r\n",
      "                        with the value of the environment variable \"<ENV>\". If the\r\n",
      "                        environment variable is not set it's an error.\r\n",
      "                        \t\"%h\" in the process name string is replaced with\r\n",
      "                        the hostname of the system.\r\n",
      "                        \t\"%%\" in the process  name string is replaced with\r\n",
      "                        \"%\". Any other character following \"%\" is illegal.\r\n",
      "\r\n",
      "       --quiet\r\n",
      "                        Suppress all nvprof output.\r\n",
      "\r\n",
      "       --stream-name <name>\r\n",
      "                        Name of the CUDA stream.\r\n",
      "                        \t\"%i\" in the stream name string is replaced with the\r\n",
      "                        ID of the stream.\r\n",
      "                        \t\"%p\" in the stream name string is replaced with\r\n",
      "                        the process ID of the application being profiled.\r\n",
      "                        \t\"%q{<ENV>}\" in the stream name string is replaced\r\n",
      "                        with the value of the environment variable \"<ENV>\". If the\r\n",
      "                        environment variable is not set it's an error.\r\n",
      "                        \t\"%h\" in the stream name string is replaced with\r\n",
      "                        the hostname of the system.\r\n",
      "                        \t\"%%\" in the stream name string is replaced with\r\n",
      "                        \"%\". Any other character following \"%\" is illegal.\r\n",
      "\r\n",
      "  -o,  --export-profile <filename>\r\n",
      "                        Export the result file which can be imported later or opened\r\n",
      "                        by the NVIDIA Visual Profiler.\r\n",
      "                        \t\"%p\" in the file name string is replaced with the\r\n",
      "                        process ID of the application being profiled.\r\n",
      "                        \t\"%q{<ENV>}\" in the file name string is replaced\r\n",
      "                        with the value of the environment variable \"<ENV>\". If the\r\n",
      "                        environment variable is not set it's an error.\r\n",
      "                        \t\"%h\" in the file name string is replaced with the\r\n",
      "                        hostname of the system.\r\n",
      "                        \t\"%%\" in the file name string is replaced with \"%\".\r\n",
      "                        \tAny other character following \"%\" is illegal.\r\n",
      "                        By default, this option disables the summary output. Note:\r\n",
      "                        If the application being profiled creates child processes,\r\n",
      "                        or if '--profile-all-processes' is used, the \"%p\" format\r\n",
      "                        is needed to get correct export files for each process.\r\n",
      "\r\n",
      "  -f,  --force-overwrite\r\n",
      "                        Force overwriting all output files (any existing files will\r\n",
      "                        be overwritten).\r\n",
      "\r\n",
      "  -i,  --import-profile <filename>\r\n",
      "                        Import a result profile from a previous run.\r\n",
      "\r\n",
      "       --log-file <filename>\r\n",
      "                        Make nvprof send all its output to the specified file, or\r\n",
      "                        one of the standard channels. The file will be overwritten.\r\n",
      "                        If the file doesn't exist, a new one will be created.\r\n",
      "                        \t\"%1\" as the whole file name indicates standard output\r\n",
      "                        channel (stdout).\r\n",
      "                        \t\"%2\" as the whole file name indicates standard error\r\n",
      "                        channel (stderr). Note: This is the default.\r\n",
      "                        \t\"%p\" in the file name string is replaced with the\r\n",
      "                        process ID of the application being profiled.\r\n",
      "                        \t\"%q{<ENV>}\" in the file name string is replaced\r\n",
      "                        with the value of the environment variable \"<ENV>\". If the\r\n",
      "                        environment variable is not set it's an error.\r\n",
      "                        \t\"%h\" in the file name string is replaced with the\r\n",
      "                        hostname of the system.\r\n",
      "                        \t\"%%\" in the file name is replaced with \"%\".\r\n",
      "                        \tAny other character following \"%\" is illegal.\r\n",
      "\r\n",
      "       --print-nvlink-topology\r\n",
      "                        Print nvlink topology \r\n",
      "\r\n",
      "  -h,  --help\r\n",
      "                        Print this help information.\r\n",
      "\r\n",
      "  -V,  --version\r\n",
      "                        Print version information of this tool.\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "!nvprof --help"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
